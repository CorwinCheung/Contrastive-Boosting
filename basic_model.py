# -*- coding: utf-8 -*-
"""basic_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13-KXhGRUFT4GjvSoYADk5hugzCkVaizk

**Building Encoder Using Contrastive Loss & Contrastive Data Augmentation**

Plan of Attack
1. Use aif360 pip package to download multiple fairness datasets (start with Adult, German, and COMPAS) and **figure out a way to clean. (aif360.datasets.StandardDataset)**. Download files from error message.
2. Find code for contrastive loss pretrainer for tabular data, generate pos. + neg. pairs & implement contrastive loss.
  *   Generate pairs based off every sample in the data but switch the protected attributes - make sure these are positive pairs.
  *   Generate negative pairs based off a couple of sample pairs in the data that are mapped differently. We want to make sure that this performs the same regardless of switch of protected attributes.
  *   Add synthetic data for contrastive learning process
  *   Implement contrastive loss for the tabular data, specific function we are using: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1640964
  *  **Use pytorch-scarf as inspiration**
3. Find boosting code
  *   Individually fair gradient boosting. (**Ask authors?**)
4. Generate test pairs for fairness (test to see if model acts differently based on protected attribute). Test fairness and accuracy
5. See how accuracy and fairness differs based on naive model, naive model with contrastive pre-trainer, naive model with boosting, and naive model with boosting and CL
6. MAKE SURE OUR APPROACH IS NOVEL - FIND MORE REASONS TO SEPARATE OUR WORK FROM OTHERS.

Notes for why our approach is novel - existing pdapers in the literature seem to be interested in fairness of CL when used in terms of group fairness metrics, not IF. Additionally, most experiments in the literature only focus on mediums like images or text. We focus on tabular data. Further, we combine it in conjunction with boosting. This is important because CL reduces annotation costs which may make AF research more efficient. The addition of boosting may allow for additional generalizability.
"""

# !pip install aif360``
# import os
# print(os.popen('which python3').read())
# Package install datasets
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from aif360.sklearn.datasets import fetch_adult, fetch_lawschool_gpa, fetch_compas
from sklearn.preprocessing import MinMaxScaler

'''
Steps to preprocess
1. Handle missing values
2. handle noisy data and outliers
3. Encode categorical data
4. feature scaling
5. split into train and test set
'''

dataset = "adult" # Either compas, lawschool, or adult
if dataset == "adult":
    X, y, _ = fetch_adult()
    X.index = y.index = pd.MultiIndex.from_arrays(X.index.codes, names=X.index.names)
    y = pd.Series(y.factorize(sort=True)[0], index=y.index, name=y.name)
    X = pd.get_dummies(X, prefix_sep='__', drop_first=True)
    X = X.reset_index()
    y = y.reset_index()
    X.fillna(0,inplace=True)
    X_test, X_train, y_test, y_train = train_test_split(X, y, train_size=16281, shuffle=False)

elif dataset == "lawschool":
    X_train, y_train = fetch_lawschool_gpa("train", numeric_only=True)
    X_test, y_test = fetch_lawschool_gpa("test", numeric_only=True)
    scaler = MinMaxScaler()
    X_train  = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)
    X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)

elif dataset == "compas":
    cols = ['sex', 'race', 'age_cat', 'priors_count', 'c_charge_degree']
    X, y = fetch_compas(usecols=cols, binary_race=True)

    # Quantize priors count between 0, 1-3, and >3
    X['priors_count'] = pd.cut(X['priors_count'], [-1, 0, 3, 100],
                              labels=['0', '1 to 3', 'More than 3'])
    X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=3694, shuffle=True, random_state=0)

else:
    print("Error! Dataset not found.")

protected = ["race", "sex"]

def generate_positive_pairs(data):
    positive_pairs = []
    for index, row in data.iterrows():
        copy = row.copy()
        for attribute in protected:
            copy[attribute] = 1 - row[attribute]
        positive_pairs.append((row, copy, 1)) # 1 indicates positive pair

    return positive_pairs

def generate_negative_pairs(data, labels, outcome_name):
    negative_pairs = []
    outcomes = {}
    for index, row in labels.iterrows():
        outcomes[row[outcome_name]] = outcomes.get(row[outcome_name], [])
        outcomes[row[outcome_name]].append(index)

    for i in outcomes[0][:5]:
        for j in outcomes[1][:5]:
            row_i, row_j = data.iloc[i], data.iloc[j]
            copy_i, copy_j = row_i.copy(), row_j.copy()
            for attribute in protected:
                copy_i[attribute] = 1 - row_i[attribute]
                copy_j[attribute] = 1 - row_j[attribute]
            negative_pairs.append((copy_i, copy_j, 0)) # 0 indicates negative

    return negative_pairs

def combine_pairs(pos_pairs, neg_pairs):
    combined_pairs = pos_pairs + neg_pairs
    n = len(combined_pairs)
    features = []
    pairs = []
    labels = []
    pair_index = 0
    for i in range(n):
        row_1, row_2, label = combined_pairs[i]
        features.append(row_1)
        features.append(row_2)
        pairs.append((pair_index, pair_index + 1))
        pair_index += 2
        labels.append(label)

    return np.array(features).astype(float), np.array(pairs), np.array(labels)


positive_pairs = generate_positive_pairs(X_train)
negative_pairs = generate_negative_pairs(X_train, y_train, "annual-income")
features, pairs, labels = combine_pairs(positive_pairs, negative_pairs)

import torch
import torch.nn as nn

class SimpleEmbeddingNet(nn.Module):
    def __init__(self, input_size, embedding_size):
        super(SimpleEmbeddingNet, self).__init__()
        self.linear = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Linear(128,128),
            nn.ReLU(),
            nn.Linear(128, embedding_size)
        )

    def forward(self, x):
        return self.linear(x)

def contrastive_loss(y, output1, output2, margin=1.0):
    euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)
    loss = 0.5 * ((1 - y) * torch.pow(euclidean_distance, 2) +
                  y * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2))
    return loss.mean()


from torch.utils.data import Dataset, DataLoader

class PairedDataset(Dataset):
    def __init__(self, features, pairs, labels):
        self.features = features
        self.pairs = pairs
        self.labels = labels

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        idx1, idx2 = self.pairs[idx]
        return self.features[idx1], self.features[idx2], self.labels[idx]

# Training Loop
dataset = PairedDataset(features, pairs, labels)
data_loader = DataLoader(dataset, batch_size=10, shuffle=True)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleEmbeddingNet(input_size=len(features[0]), embedding_size=20).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(10):  # Train for 10 epochs
    model.train()
    total_loss = 0
    for data1, data2, label in data_loader:
        data1, data2, label = data1.to(device).float(), data2.to(device).float(), label.to(device).float()
        optimizer.zero_grad()
        # Generate embeddings
        output1 = model(data1)
        output2 = model(data2)

        # Compute contrastive loss
        loss = contrastive_loss(label.float(), output1, output2)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(data_loader)}")

datapoint = torch.tensor([ 1.,  1., 31., 10.,  0.,  0., 80.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,
         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])

print(len(datapoint))

print(model(datapoint))

unique_values, counts = np.unique(labels, return_counts=True)

# Print each unique value with its count
for value, count in zip(unique_values, counts):
    print(f"Value: {value}, Count: {count}")

# Extract embeddings
from tqdm.auto import tqdm
def dataset_embeddings(model, loader, device):
    model.to(device)
    model.eval()  # Set model to evaluation mode
    embeddings = []

    with torch.no_grad():  # Disable gradient calculation
        for data, labels in tqdm(loader):  # Assuming the loader gives us a tuple of (data, labels)
            data = data.to(device)
            embedding = model(data)  # Get the embedding of the data
            embeddings.append(embedding)

    return torch.cat(embeddings).cpu().numpy()

print(X_train.values[0])

# Create dataloaders for test
import torch
from torch.utils.data import TensorDataset, DataLoader

#convert boolean values of X_train to 1s and 0s before tensoring them
X_train = X_train.astype(int)
X_test = X_test.astype(int)
X_train.fillna(0, inplace=True)
X_test.fillna(0, inplace=True)

#convert to tensors
X_train_tensor = torch.tensor(np.array(X_train.values), dtype=torch.float32)
y_train_tensor = torch.tensor(np.array(y_train.values.squeeze()), dtype=torch.long)  # Assuming classification task

X_test_tensor = torch.tensor(np.array(X_test.values), dtype=torch.float32)
y_test_tensor = torch.tensor(np.array(y_test.values.squeeze()), dtype=torch.long)

train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
test_dataset = TensorDataset(X_test_tensor, y_test_tensor)

batch_size = 64

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print(len(X_train_tensor[0]))
print("Shape of X_train:", X_train.shape)
print("Shape of X_train_tensor:", X_train_tensor.shape)

print(len(y_train_tensor))

# Test embeddings on logistic regression model with just X_test vs. with embeddings

# IDEA - copy some of the vanilla vs embedding stuff here: https://github.com/clabrugere/pytorch-scarf/blob/master/example/example.ipynb

import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix
lr = LogisticRegression(max_iter=1000)

# Assuming adult dataset
# y_train = y_train.drop(columns=protected)
# y_test = y_test.drop(columns=protected)


# 1. Trained on original dataset
lr.fit(X_train, y_train["annual-income"])
vanilla_predictions = lr.predict(X_test)
print(classification_report(y_test["annual-income"], vanilla_predictions))
cm = confusion_matrix(y_test["annual-income"], vanilla_predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)

fig, ax = plt.subplots(figsize=(5, 5))
disp.plot(ax=ax)

# 2. Trained on embeddings

# get embeddings for training and test set
train_embeddings = dataset_embeddings(model, train_loader, device)
test_embeddings = dataset_embeddings(model, test_loader, device)

import torch

# Assuming you have a DataLoader named 'dataloader'
# Iterate through the first few batches
num_elements_to_print = 5
elements_printed = 0

for batch_data in train_loader:
    for i in range(len(batch_data)):
        print(batch_data[0])
        print(len(batch_data[0]))
        elements_printed += 1
        if elements_printed >= num_elements_to_print:
            break
    if elements_printed >= num_elements_to_print:
        break

lr.fit(train_embeddings, y_train["annual-income"])
vanilla_predictions = lr.predict(test_embeddings)

print(classification_report(y_test["annual-income"], vanilla_predictions))
cm = confusion_matrix(y_test["annual-income"], vanilla_predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)

fig, ax = plt.subplots(figsize=(5, 5))
disp.plot(ax=ax)

#Visualizing the embeddings with T-sne
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2)
reduced = tsne.fit_transform(train_embeddings[:200])
positive = y_train["annual-income"][:200] == 1

fig, ax = plt.subplots(figsize=(5, 5))

ax.scatter(reduced[positive, 0], reduced[positive, 1], label="positive")
ax.scatter(reduced[~positive, 0], reduced[~positive, 1], label="negative")
plt.legend()

#2. Pass these embeddings into the model for individually fair gradient boosting

#Evaluate Individual Fairness - also might be helpful to look at individually fair gradient boosting code
def generate_synthetic_samples(data: pd.DataFrame, num_samples=10):
    min_values = data.min()
    max_values = data.max()

    synthetic_samples = pd.DataFrame(columns=data.columns)

    for col in data.columns:
        if col in protected:
            synthetic_col = np.random.choice([0, 1], size=num_samples)

        if data[col].dtype == bool:
            synthetic_col = np.random.choice([True, False], size=num_samples)

        else:
            min_val = min_values[col]
            max_val = max_values[col]
            synthetic_col = np.random.uniform(min_val, max_val, num_samples)

        synthetic_samples[col] = synthetic_col
    return synthetic_samples

def generate_eval_pairs(data):
    pairs = []
    for _, row in data.iterrows():
        copy = row.copy()
        for attribute in protected:
            copy[attribute] = 1 - row[attribute]

        pairs.append((row, copy))

    return pairs

#Compare to previous approaches: eg. naive model, naive model + Individually fair gradient boosting
#naive model with contrastive pre-trainer